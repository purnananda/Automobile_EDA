{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis - Automobile (Part 1: Data Cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"600\" height=\"400\" style=\"float: left;\" src=\"Images/Automobile_EDA_Banner.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. About the Dataset:</h3>\n",
    "<p>This dataset consist of data From 1985 Ward's Automotive Yearbook. Here are the sources:</p>\n",
    "\n",
    "<ul>\n",
    "    <li>1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook.</li>\n",
    "    <li>Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038.</li>\n",
    "    <li>Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This data set consists of three types of entities: </p>\n",
    "<ol>\n",
    "    <li>the specification of an auto in terms of various characteristics,</li>\n",
    "    <li>its assigned insurance risk rating,</li>\n",
    "    <li>its normalized losses in use as compared to other cars.</li>\n",
    "</ol>\n",
    "<p>The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process \"symboling\". A value of <b>+3</b> indicates that the auto is risky, <b>-3</b> that it is probably pretty safe.</p>\n",
    "<p>For more details about the dataset, please visit <a href=\"https://archive.ics.uci.edu/ml/datasets/automobile\">here</a>.</p>\n",
    "\n",
    "#### Dataset Attribute Information:\n",
    "Attribute: Attribute Range \n",
    "\n",
    "1. symboling: -3, -2, -1, 0, 1, 2, 3. \n",
    "2. normalized-losses: continuous from 65 to 256. \n",
    "3. make: \n",
    "alfa-romero, audi, bmw, chevrolet, dodge, honda, \n",
    "isuzu, jaguar, mazda, mercedes-benz, mercury, \n",
    "mitsubishi, nissan, peugot, plymouth, porsche, \n",
    "renault, saab, subaru, toyota, volkswagen, volvo \n",
    "\n",
    "4. fuel-type: diesel, gas. \n",
    "5. aspiration: std, turbo. \n",
    "6. num-of-doors: four, two. \n",
    "7. body-style: hardtop, wagon, sedan, hatchback, convertible. \n",
    "8. drive-wheels: 4wd, fwd, rwd. \n",
    "9. engine-location: front, rear. \n",
    "10. wheel-base: continuous from 86.6 120.9. \n",
    "11. length: continuous from 141.1 to 208.1. \n",
    "12. width: continuous from 60.3 to 72.3. \n",
    "13. height: continuous from 47.8 to 59.8. \n",
    "14. curb-weight: continuous from 1488 to 4066. \n",
    "15. engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor. \n",
    "16. num-of-cylinders: eight, five, four, six, three, twelve, two. \n",
    "17. engine-size: continuous from 61 to 326. \n",
    "18. fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi. \n",
    "19. bore: continuous from 2.54 to 3.94. \n",
    "20. stroke: continuous from 2.07 to 4.17. \n",
    "21. compression-ratio: continuous from 7 to 23. \n",
    "22. horsepower: continuous from 48 to 288. \n",
    "23. peak-rpm: continuous from 4150 to 6600. \n",
    "24. city-mpg: continuous from 13 to 49. \n",
    "25. highway-mpg: continuous from 16 to 54. \n",
    "26. price: continuous from 5118 to 45400."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Problem Statement:</h3>\n",
    "<p>As part of Exploratory Data Analysis (EDA), The notebook will explore the following things from the Automobile dataset: </p>\n",
    "<ul>\n",
    "    <li>Finding patterns in Data</li>\n",
    "    <li>Determining relationships in Data</li>\n",
    "    <li>Checking of assumptions</li>\n",
    "    <li>Draw the conclusion</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the data, cleanse the data when there is needed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Importing packages    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Automobile dataset from CSV file.\n",
    "df = pd.read_csv('data/Automobile_data.csv')\n",
    "\n",
    "# df = pd.read_csv('data/Automobile_data.csv', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Data Pre-Profiling\n",
    "Review the data types and sample data to understand what variables we are dealing with?<br />\n",
    "Which variables need to be transformed in some way before they can be analyzed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the dimensions of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No of Rows: 205, and No of Columns: 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the header data.\n",
    "#df.head() \n",
    "\n",
    "# See the data frame high leve info, like: Row count, Columns and types, Memory usage, etc. \n",
    "df.info()\n",
    "\n",
    "# Describe the dataset.  \n",
    "#df.describe()\n",
    "\n",
    "# Get the list of columns.\n",
    "#df.columns\n",
    "\n",
    "# See the columns and types.\n",
    "# df.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the header rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the dataframe head.  \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics for the numerical variables\n",
    "# df.describe(include = 'all') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check any NULL value present in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the NULL check above, no null value found. May be in this dataset we might have null value with different text or symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre profilling for dataframe and null values detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pandas profilling - once.\n",
    "#!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_profiling                                                     # Get a quick overview for all the variables using pandas_profiling                                         \n",
    "# profile = pandas_profiling.ProfileReport(df)\n",
    "# profile.to_file(output_file=\"Pre_Automobile_EDA_Output.html\")                    # HTML file will be downloaded to your workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/pre-profilling.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "As we can see there is huge discrepancies in normalize losses column and few others columns as well, where we can observed \"?\" symbol is used in place of NULL value. Let's detect  all the null values present in the dataset and clean it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the columns where we have missing data as \"?\" symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns that contain a \"?\" for missing data\n",
    "cols = list(df.columns)\n",
    "for col in cols:\n",
    "    if('?' in df[col].value_counts()):\n",
    "        print(col + \" - \" + str(df[col].value_counts()['?']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will have to repace missing data <b>(\"?\")</b> as NAN, so that further it will help us cleanup the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\", np.NAN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see now, NAN value in data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Cleaning:\n",
    "Following columns need to be cleanup, as we will be using them for our analysis. \n",
    "* normalized-losses - 41\n",
    "* num-of-doors - 2\n",
    "* bore - 4\n",
    "* stroke - 4\n",
    "* horsepower - 2\n",
    "* price - 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1. Cleaning the normalized-losses data\n",
    "\n",
    "* a. Convert \"normalized-losses\" column to numeric. In the process, insert NaNs where values cannot be converted to a number\n",
    "* b. Under each make, if there are enough number of records with valid loss values (>=50%), find their mean value and replace NaNs.  \n",
    "* c. If more than 50% records under a make have NaNs for loss value, those records have to be discarded for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dataframe analysis for normalized-losses column: \n",
    "\n",
    "df_auto = df\n",
    "\n",
    "#Replace non-numeric characters in normalized-losses column with NaN.\n",
    "df_auto['normalized-losses'] = pd.to_numeric(df_auto['normalized-losses'], errors='coerce')\n",
    "\n",
    "# Find makes having normalized-losses as NaNs and their number of occurrances.\n",
    "carsnan = df_auto[df_auto['normalized-losses'].isnull()].groupby(by='make', as_index=False).size().reset_index()\n",
    "carsnan.columns = ['make','nanscount']\n",
    "\n",
    "#Find makes with count of all records under each make\n",
    "carsgp = df_auto.groupby(by='make', as_index=False).size().reset_index()\n",
    "carsgp.columns=['make','makecount']\n",
    "carsgpnan=carsgp.merge(carsnan,on=\"make\", how=\"left\", suffixes=['', '_right'])\n",
    "\n",
    "#carsgpnan\n",
    "\n",
    "#Find makes having more than 50% records with valid normalized-losses values\n",
    "mean_nan_makes = carsgpnan[carsgpnan['nanscount']*100/carsgpnan['makecount'] <= 50].reset_index()\n",
    "mean_nan_makes['nlimpute']=mean_nan_makes['make']\n",
    "\n",
    "#Find mean loss figures for those makes\n",
    "nlcars=df_auto.merge(mean_nan_makes, on=\"make\", how=\"left\", suffixes=['','_right'])\n",
    "nlmean_by_make = nlcars.groupby(by='nlimpute')['normalized-losses'].mean().reset_index()\n",
    "\n",
    "#Replace NaN values with the calculated mean\n",
    "carsr=df_auto.merge(nlmean_by_make, how=\"left\", left_on=\"make\", right_on=\"nlimpute\", suffixes=['', '_right'])\n",
    "\n",
    "carsr['normalized-losses'] = np.where(carsr['normalized-losses'].isnull(), carsr['normalized-losses_right'], carsr['normalized-losses']) \n",
    "\n",
    "cars = carsr.loc[carsr['normalized-losses'].isnull()==False].copy()\n",
    "print(\"Column normalized-losses has \" + str(cars['normalized-losses'].count()) + \" values after cleaning\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2. Cleaning the price data\n",
    "\n",
    "* Calculate the average price per make and impute the missing price values with the respective make's average price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['price'] = pd.to_numeric(cars['price'],errors='coerce')\n",
    "mean_price_by_make = cars.groupby(by=['make'])['price'].mean().reset_index()\n",
    "\n",
    "cars = cars.merge(mean_price_by_make,on='make', suffixes=['', '_right'])\n",
    "cars['price'] = np.where(cars['price'].isnull(), cars['price_right'], cars['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3. Cleaning the horsepower data\n",
    "\n",
    "* Convert to numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['horsepower'] = pd.to_numeric(cars['horsepower'], errors=\"coerce\")\n",
    "cars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4. Cleaning the num-of-doors data\n",
    "\n",
    "* Remove records where number of doors having null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars[cars['num-of-doors'].isnull()]\n",
    "cars = cars[cars['num-of-doors'].notna()] # Remove 'num-of-doors' values.\n",
    "cars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5. Cleaning the peak-rpm data\n",
    "* Convert peak-rpm data in to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the non-numeric data to null and convert the datatype.\n",
    "cars['peak-rpm'] = pd.to_numeric(cars['peak-rpm'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6. Cleaning the Bore & Stroke data\n",
    "\n",
    "* Remove records where Bore & Stroke having null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars[cars['bore'].notna()]\n",
    "cars = cars[cars['stroke'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all temporary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cars['normalized-losses_right']\n",
    "del cars['price_right']\n",
    "del cars['nlimpute']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert text columns to integer\n",
    "Following columns are in text forms and need to be interpreted into intiger form.\n",
    "* num-of-doors\n",
    "* num-of-cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"num-of-doors\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"num-of-cylinders\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to return the respective integer value for a number string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the respective integer value for a number string.\n",
    "def get_number(inputStr):\n",
    "    '''\n",
    "    Get the respective integer value for a number string.\n",
    "    '''\n",
    "    switcher = {\n",
    "        \"two\": 2,\n",
    "        \"three\": 3,\n",
    "        \"four\": 4,\n",
    "        \"five\": 5,\n",
    "        \"six\": 6,\n",
    "        \"seven\": 7,\n",
    "        \"eight\": 8\n",
    "    }\n",
    "    return switcher.get(inputStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_number(\"seven\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['num_doors'] = cars['num-of-doors'].apply(lambda x: get_number(x))\n",
    "cars['num_cylinders'] = cars['num-of-cylinders'].apply(lambda x: get_number(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Engine size:</b> The size of an engine is measured in cubic centimetres (cc) and refers to the total volume of air and fuel thatâ€™s pushed through the engine by its cylinders. <br />\n",
    "<b>Power to Weight ratio:</b> Power to weight ratio shows the performance of a car. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Derive columns: \n",
    "* Convert the Engine size from cubic inches to cubic centimeters (cc) for better understanding. To convert cubic inch to cubic centimeter, divide cubic inch value by 0.061024\n",
    "\n",
    "* Calculate power to weight ratio of vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['engine_size_cc'] = cars['engine-size'].apply(lambda x: int(x/0.061024))\n",
    "cars['power_to_weight_ratio'] = pd.to_numeric(cars['horsepower'], errors=\"coerce\")/cars['curb-weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create two columns - Risky and Safe based on symboling data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risky_or_safe(x):\n",
    "    if (x > 0):\n",
    "        return 'risky'\n",
    "    return 'safe'\n",
    "\n",
    "def is_risky(x):\n",
    "    if (x > 0):\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "cars['risky_or_safe'] = cars['symboling'].apply(lambda x: risky_or_safe(x))\n",
    "cars['is_risky'] = cars['symboling'].apply(lambda x: is_risky(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace Drive-Wheels value with descriptive columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"drive-wheels\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the descriptive text for Drive-Wheels.\n",
    "def get_descriptive_text(inputStr):\n",
    "    '''\n",
    "    Get the descriptive text for Drive-Wheels.\n",
    "    '''\n",
    "    switcher = {\n",
    "        \"4wd\": \"Four Wheel Drive\",\n",
    "        \"fwd\": \"Front Wheel Drive\",\n",
    "        \"rwd\": \"Rear Wheel Drive\"\n",
    "    }\n",
    "    return switcher.get(inputStr)\n",
    "\n",
    "# get_descriptive_text(\"4wd\")\n",
    "cars['drive-wheels'] = cars['drive-wheels'].apply(lambda x: get_descriptive_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if any value is NULL? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#List of columns that contain a Null value.\n",
    "cols = list(cars.columns)\n",
    "for col in cols:\n",
    "    if(cars[col].isnull().sum() > 0):\n",
    "        print(col + \" - \" + str(cars[col].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Post-Profiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas_profiling\n",
    "#profile = pandas_profiling.ProfileReport(cars)\n",
    "#profile.to_file(output_file=\"Post_Automobile_EDA_Output.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cleaned and output CSV file for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars.to_csv('data/Automobile_data_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
